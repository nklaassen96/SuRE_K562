# This script is designed to process generated by the SuRE-Pipeline
# to get a general overview of the data quality. 

# First load the required libraries
# NO LIBRARIES NEEDED YET
library(data.table)
library(tidyverse)

#### Loading the SNPtxt files into R ####
# This can be done with the txt.gz files directly and do not need 
# to be unzipped

dir <- "/DATA/usr/n.klaassen/projects/SuRE_K562/data/processed/SuRE_output/SuRE-counts_"

#for (chrom in paste0("chr", c(1:22, "X"))){ #THIS FUNCTION TAKES 30 MIN TO COMPLETE!!!!
  #READ TXT.GZ
    tab <- fread(paste0(dir, chrom, ".txt.gz"), header = TRUE, sep = "\t", stringsAsFactors = FALSE)
    print(paste0(chrom, " is read at", Sys.time()))
  
  #SEPARATE ROWS
    name <- paste0("sure", chrom)
    tabsep <- separate_rows(tab, SNPrelpos:SNPidx, SNPbaseInf:PAT_MAT, sep = ",") 
    assign(name, tabsep)
    print(paste0(chrom, " is separated at", Sys.time()))
  
  #WRITE SEPARATE TXT FILES
    write.table(get(paste0("sure", chrom)), paste0("/DATA/usr/n.klaassen/projects/SuRE_K562/data/processed/SuRE_Counts_Separated_20190917/SuRE-Counts_Separated_", chrom,  ".txt"), 
            quote = FALSE, 
            sep = "\t", 
            row.names = FALSE, 
            col.names = TRUE)
    print(paste0(chrom, "is writen to .txt file at ", Sys.time()))
#}

####  READ & CONCATONATE SEPARATED FILES ####
sure = NULL
for (chrom in paste0("chr", c(1:22, "X"))){
  assign(paste0("sure", chrom), fread(paste0("/DATA/usr/n.klaassen/projects/SuRE_K562/data/processed/SuRE_Counts_Separated_20190917/SuRE-Counts_Separated_", chrom,  ".txt"), 
             header = TRUE, 
             sep = "\t", 
             stringsAsFactors = FALSE,
             na.strings = NULL))
  print(paste0(chrom," is read"))
  sure <- rbind(sure, get(paste0("sure", chrom)))
  print(paste0(chrom, " is added to datatable"))
  rm(list=paste0("sure", chrom))
}

############################################
#### Summarize biological replicates #######
############################################

sure$SuRE_B1 <- sure$SuRE23_45_B1_T1+sure$SuRE23_45_B1_T2+sure$SuRE23_45_B1_T3+sure$SuRE23_45_B1_T4
sure$SuRE_B2 <- sure$SuRE23_55_B2_T1+sure$SuRE23_55_B2_T2
sure$SuRE_B  <- sure$SuRE_B1+sure$SuRE_B2
sure$cDNA.normby.ipcr <- sure$SuRE_B / sure$iPCR

surevar <- na.omit(sure) #Remove gDNA counts without variants ~50% removed
suretst1 <- surevar[surevar$SNPvar != 3 & surevar$SNPvar != 2]

#snp id for which there is a ref and alt allele (could be cDNA count = 0)
ref.alt.snp.id <- names(tapply(surevar$SNPvar, surevar$SNP_ID, function(x){all(c(0,1) %in% x)}))
suretst1 <- surevar[surevar$SNP_ID %in% cosmic.overlap.snp.id]                
suretst2 <- suretst1[suretst1$SNPvar != 3 & suretst1$SNPvar != 2]                
##################################################
#### General Statistics ##########################
##################################################

tst1 <- table(sure$SNPbaseInf)
sum(tst1[c(2:4,10)])/sum(tst1[2:11]) #Fraction known (A,C,G,T) bases
tst2 <- table(sure$SNPvar)
sum(tst2[1:3])/sum(tst2) #Fraction of bases that are reference (0), alternative (1) or not matching (2)

uniknown <- sum(grepl("rs", sureuni$SNP_ID)) #amount known variants
uniunknown <- sum(grepl("chr", sureuni$SNP_ID)) #amount unknown variants

countpervariant <- as.data.frame(tapply(sure$SuRE_B, sure$SNP_ID, function(x){sum(x, na.rm = TRUE)})) #SuRE-counts per SNP_ID; first row should be deleted
countpervariant <- data.frame(countpervariant[-1,], row.names = rownames(countpervariant)[-1])
colnames(countpervariant) <- "FREQ"
boxplot(countpervariant$FREQ,col = 2, ylab = "Transcript reads (B1 + B2)")
summary(countpervariant$FREQ)

sum(grepl("chr", rownames(countpervariant))) #Amount of unique novel variants
sum(countpervariant$FREQ > 0) # amount of variants with cDNA counts higher than 10
sum(countpervariant$FREQ > 10 & grepl("chr", rownames(countpervariant))) #amount of novel variants with cDNA counts higher than 10

##########################################################################################
# KEEP ONLY VARIANTS THAT HAVE >0 REF ALLELE (SNPvar = 0) AND >0 ALT ALLELE (SNPvar = 1) #
##########################################################################################

s1 <- sure[sure$SNPvar != 3 & sure$SNPvar != 2]
print(paste0(100-nrow(s1)/nrow(sure)*100, "% is removed due to removal of counts containing no variants and counts containing ambiguous bases"))
c1 <- as.data.frame(as.matrix(tapply(s1$SNPvar, s1$SNP_ID, function(x){length(table(x))})))
n <- rownames(c1)[c1$V1 == 2]
nchr <- n[grepl("chr", n)]
length(nchr)
surealtref <- sure[sure$SNP_ID %in% nchr,] #contains names of NOVEL variants that haveref en alt
surealtref2 <- surealtref[surealtref$SNPvar != 3 & surealtref$SNPvar != 2] #AND only containing rows with nonambiguos bases
length(unique(surealtref2$SNP_ID))

countpervariantNRA <- as.data.frame(tapply(surealtref2$SuRE_B, surealtref2$SNP_ID, sum))
colnames(countpervariantNRA) <- "FREQ"
nNRAC<- rownames(countpervariantNRA)[countpervariantNRA$FREQ > 10]

sureNRAC <-surealtref2[surealtref2$SNP_ID %in% nNRAC,]
sureNRAC <- sureNRAC[sureNRAC$SNPvar != 3 & sureNRAC$SNPvar != 2]
barcodes.per.variant <- tapply(sureNRAC$chr, sureNRAC$SNP_ID, length)



########################
# Prepare SNVs looping #
########################

  # define the sure dataframe that will be used
  sure.set <- suretst2
  

  # The first colomn in snp.names could be "", indicating the gDNA fragments that have no SNPs in them
  # This row should be removed if it is present

  if (unique(sure.set$SNP_ID)[1] == ""){
    snp.names <- unique(sure.set$SNP_ID)[2:length(snp.names)]}else{
    snp.names <- unique(sure.set$SNP_ID)
  }

  # Generate a dataframe to which the results below can be stored  
  results.sure <- data.frame(matrix(nrow= length(snp.names), ncol = 9))
  colnames(results.sure) = c("chr", "snp.abs.pos", "SNP_ID", "ref.element.count", "alt.element.count", "ref.cDNA.mean", "alt.cDNA.mean", "wilcox.pvalue", "variant")

##############################################
# Prepare variant (e.g. promoter) annotation #
##############################################  
  
  library(TxDb.Hsapiens.UCSC.hg19.knownGene)
  library(VariantTools)
  library(dplyr)
  txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
  
  # Generate a granges file from the results.sure dataframe
  snp.granges <- reduce(GRanges(seqnames = sure.set$chr, ranges = IRanges(start = sure.set[,SNPabspos],end = sure.set[,SNPabspos])))
  
  # Locate variants
  variants.granges <- locateVariants(snp.granges, txdb, AllVariants())
  
  # Save variants in a dataframe
  df.chr <- seqnames(variants.granges)
  df.snp.abs.pos <- start(variants.granges)
  df.snp.pos <- paste0(df.chr,":", df.snp.abs.pos)
  df.variant <- variants.granges$LOCATION
  variants.df <- data.frame(df.chr, df.snp.abs.pos, df.snp.pos, df.variant)
  
  # Use the distinct function from dplyr to remove identical rows
  # These could for example contain multiple rows that contain an 
  # intron
  
  variants.df.nonredundant <- distinct(variants.df)
  
  
##########################################
# Start actual loop through all the SNVs #
##########################################

for (i in 1:length(snp.names)){
  
  if (i %% 100 == 0) {print(i)}
  
  
  # Retrieve rownumbers of the respective SNP and
  # generate a small dataframe containing the desired variant
  snp.idx <- which(sure.set$SNP_ID == snp.names[i])
  sure.snp <- sure.set[snp.idx]
  
  ref <- which(sure.snp$SNPvar == 0)
  alt <- which(sure.snp$SNPvar == 1)
  
  
  
  # Assign variables that are constant per variant (chromosome, absolute position and SNPid)
  results.sure[i, "chr"] <- sure.snp[1]$chr
  results.sure[i, "snp.abs.pos"] <- sure.snp[1]$SNPabspos
  results.sure[i, "SNP_ID"] <- sure.snp[1]$SNP_ID
  
  
  
  # Assign the number of counts
  results.sure[i, "ref.element.count"] <- sum(sure.snp$SNPvar == 0)
  results.sure[i, "alt.element.count"] <- sum(sure.snp$SNPvar == 1)
  
  
  results.sure[i, "ref.cDNA.mean"] <- round(mean(sure.snp[ref, cDNA.normby.ipcr]), digits = 1)
  results.sure[i, "alt.cDNA.mean"] <- round(mean(sure.snp[alt, cDNA.normby.ipcr]), digits = 1)
  
  
 
  # Perform wilcoxon test if there is at least 1 ref and 1 alt sequence measured (and t.test if at least 2 for both)
  if (length(alt) >= 1 & length(ref) >= 1){
    results.sure[i, "wilcox.pvalue"] <- wilcox.test(sure.snp[ref, cDNA.normby.ipcr], sure.snp[alt, cDNA.normby.ipcr])$p.value
  }
  
  
  # Generate a unique snpi.id in the format "chr1:3824989"
  snp.id <- paste0(results.sure[i,"chr"], ":", results.sure[i, "snp.abs.pos"])
  
  
  # Generate a factor stating all variants for that specific snp (could be >1)
  # Then sort the factor based on the levels and take the first (most important)
  # variant as which we want it to classify
  
  
  #variants <- variants.df.nonredundant[variants.df.nonredundant$df.snp.pos == snp.id, "df.variant"]
  #variants.sorted <- sort(factor(variants, levels = c("promoter","spliceSite", "coding", "fiveUTR", "threeUTR","intron", "intergenic")))
  
  
  #results.sure[i,"variant"] <- as.character(variants.sorted[1])
  
}

  
# Save Results
  saveRDS(results.sure, file = "/DATA/usr/n.klaassen/projects/SuRE_K562/data/interim/R_Objects/results_cosmic_rs.rds")
#Analyse some results

snp.id = 	"rs9500231"
View(sure.set[sure.set$SNP_ID == snp.id, c("chr","start", "end", "SNP_ID", "SNPbase", "iPCR", "SuRE_B", "cDNA.normby.ipcr")])


## Try to see if i can separate SNP based on wilcoxpvalue [0-0.25 and 0.25-1 + NaN]

  tapply(results.sure$alt.cDNA.mean, results.sure$variant, function(x){mean(x, na.rm = TRUE)})
